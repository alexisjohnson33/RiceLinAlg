

\beginedxvertical{Page One}

\beginedxtext{Preliminaries}





At the end of this sequence, and after some practice, you should be able to:

\begin{itemize}
\item Understand the definition of linear independence.  
\item Be able to determine whether a list of vectors is linearly independent. 
\item Know conditions on whether a list of vectors in $\R^n$ can be linearly independent.
\end{itemize}


For time budgeting purposes, this sequence has X videos totaling X minutes, 
plus some questions.  




\endedxtext

\endedxvertical


\beginedxvertical{Linear Independence}


\beginedxproblem{Existence vs. Uniqueness}{\dpa1}

Given a matrix $A$, consider the equation $A\vecx = \veco$.   

Regarding such equations, we have discussed two main questions: the existence question
(does there exist at least one solution?) and the uniqueness question (is there at most one
solution?).  For this equation, one of these questions always has the same answer, no matter
what $A$ is.  Which question does not always have the same answer?  

\edXabox{expect="Uniqueness" options="Existence","Uniqueness"}

\edXsolution{Because $A\cdot\veco = \veco$ always, the answer to the existence question is always "yes" for this equation. It's not always the case, however, that the zero vector is the only solution; for some matrices, some other combination of the columns of $A$ will also give zero. When a matrix $A$ does in fact have a unique solution to $A\vecx = \veco$, that makes $A$ a special type of matrix, as we'll see in this section.}

\endedxproblem

\doedxvideo{Linear Independence}{jQSgCZwOKQU}


\beginedxproblem{Definition}{\dpa1}


Which of these is the definition of linearly dependent?  

A list of vectors $\{v_1; v_2; \ldots v_n\}$ is linearly dependent if...

\edXabox{type="multichoice" expect="...there exist scalars
$a_1, a_2, \ldots a_n$, not all zero, such that $a_1v_1 + a_2v_2 + \ldots a_nv_n = \veco$." options="...there exist scalars
$a_1, a_2, \ldots a_n$, not all zero, such that $a_1v_1 + a_2v_2 + \ldots a_nv_n = \veco$.","...there exist scalars
$a_1, a_2, \ldots a_n$, all not zero, such that $a_1v_1 + a_2v_2 + \ldots a_nv_n = \veco$.","Both of these are the definition."}

\edXsolution{ 
We know that if all the scalars equal zero, the equation $a_1v_1 + a_2v_2 + \ldots a_nv_n = \veco$ will be true for any set $\{v_1; v_2; \ldots v_n\}$. The idea of linear dependence is that we can choose a different set of scalars that also makes the equation true; i.e., a set of scalars that is not all zeros. They may very well be all non-zero scalars, but this is not required.
}


\endedxproblem


\endedxvertical


\beginedxvertical{Linear Independence Problems}


\beginedxtext{Definitions of Linearly Independent and Dependent}

We say that a list of vectors $\{v_1; v_2; \ldots v_n\}$ in a vector space $V$ is 
{\keyb{\bf linearly independent}} if the only way to pick scalars $a_1, a_2, \ldots a_n$ such that
$a_1v_1 + a_2v_2 + \ldots + a_nv_n = \veco$ is if $a_1 = a_2 = \ldots = a_n = 0$.  

A list of vectors $\{v_1; v_2; \ldots v_n\}$ in a vector space $V$ is 
{\keyb{\bf linearly dependent}} if there are scalars $a_1, a_2, \ldots a_n$, not all zero, such that
$a_1v_1 + a_2v_2 + \ldots + a_nv_n = \veco$.  


\endedxtext

\beginedxproblem{List 1}{\dpa1}


Consider the list of vectors $\{v_1; v_2; v_3\}$, where

\[v_1 = \left[\begin{array}{c} 1 \\ -1  \\ 0 \\ 0 \end{array} \right], 
v_2 = \left[\begin{array}{c} 2 \\ -1  \\ 3 \\ 5 \end{array} \right],  
v_3 = \left[\begin{array}{c} -3 \\ 3  \\ 0 \\ 0 \end{array} \right]. \]

Can you find scalars $a_1, a_2, a_3$, not all zero, such that 
$a_1v_1 + a_2 v_2 + a_3 v_3 = \veco$?  If so, enter an example of such scalars below.
If not, enter `No'  

\edXabox{expect="Placeholder" options="Placeholder"}



Is the list $\{v_1; v_2; v_3\}$ linearly dependent or linearly independent?  

\edXabox{expect="Linearly dependent" options="Linearly dependent","Linearly independent"}


\edXsolution{ 
Notice that $v_2$ is the only vector in the set with non-zero entries in the third and fourth positions; a zero combination of these vectors therefore requires $a_2 = 0$. Then, notice that $-3 \cdot v_1 = v_3$, so that $3 \cdot v_1 + 1 \cdot v_3 = \veco$. We have that $a_1 = 3$, $a_2 = 0$, and $a_3 = 1$ is a possible set of scalars that satisfies the equation. It follows that any scalar multiple of that triple is also a set that satisfies the equation. Furthermore, it is easy to show that the coefficients that satisfy the equation can only be scalar multiples of that triple. 
\\The set $\{v_1; v_2; v_3\}$ is linearly dependent because, as we've just seen, there exist sets of coefficients, not all zero, that make the above equation true. 
}


\endedxproblem



\beginedxproblem{List 2}{\dpa1}


Consider the list of vectors $\{v_1; v_2; v_3\}$, where

\[v_1 = \left[\begin{array}{c} 1 \\ -1  \\ 3 \\ 4 \\5 \end{array} \right], 
v_2 = \left[\begin{array}{c} 0 \\ 0  \\ 0 \\ 0 \\ 0 \end{array} \right],  
v_3 = \left[\begin{array}{c} -3 \\ 3  \\ 3 \\ 5 \\ 1 \end{array} \right]. \]

Can you find scalars $a_1, a_2, a_3$, not all zero, such that 
$a_1v_1 + a_2 v_2 + a_3 v_3 = \veco$?  If so, enter an example of such scalars below.
If not, enter `No'.  

\edXabox{expect="Placeholder" options="Placeholder"}


Is the list $\{v_1; v_2; v_3\}$ linearly dependent or linearly independent?  

\edXabox{expect="Linearly dependent" options="Linearly dependent","Linearly independent"}

\edXsolution{ The first answer is immediately "yes" because we have the zero vector in our set; we can choose any non-zero value for $a_2$, and with $a_1 = 0$ and $a_3 = 0$, the above equation will still be true. Because there exist sets of coefficients, not all zero, that make the above equation true, the set $\{v_1; v_2; v_3\}$ is a linearly dependent set.
}

\endedxproblem




\beginedxproblem{List 3}{\dpa1}


Let $\mathbb{P}$ be the vector space of polynomials with real coefficients in the variable $t$.  
Consider the list of vectors $\{f; g\}$, where $f(t) = 1+t$ and $g(t) = t+t^2$ are
vectors in $\mathbb{P}$.

Can you find scalars $a_1, a_2$, not both zero, such that 
$a_1f + a_2 g = \veco$?  If so, enter an example of such scalars below.
If not, type `No'.  

\edXabox{expect="Placeholder" options="Placeholder"}


Is the list $\{v_1; v_2\}$ linearly dependent or linearly independent?  

\edXabox{expect="Linearly independent" options="Linearly dependent","Linearly independent"}

\edXsolution{ In the case of two vectors, we can determine whether they are linearly independent or not by examination. If we see that the vectors are scalar multiples of each other, we know it will be possible to add non-zero multiples of them to get zero, and they are therefore linearly dependent as a set. If we see that they are not scalar multiples of each other, we know there can't be a way to add non-zero multiples of them to get zero, and they are therefore linearly independent. The case of $f$ and $g$ above is the latter situation; no scalar, multiplied by $f$, would give us $g$.
}


\endedxproblem



\endedxvertical




\beginedxvertical{Geometry of Linear Independence}


\doedxvideo{Linear Independence for Small Sets}{Mw04hBXVtho}


\beginedxproblem{More Lists}{\dpa3}


Consider the vectors $v_1, v_2, v_3 \in \R^2$ as given in this picture:


\begin{center}
\includesvg[300]{c1s6threevectors}   
\end{center}

Which of the following lists are linearly independent?  Click all that apply.  


\edXabox{type="oldmultichoice" expect="$\{v_1\}$","$\{v_1;v_2\}$","$\{v_2;v_3\}$" options="$\{\veco\}$","$\{v_1\}$","$\{v_1;v_2\}$","$\{v_1;v_3\}$","$\{v_2;v_3\}$","$\{v_3;v_3\}$","$\{v_1; v_2; v_3\}$"}


\edXsolution{ The zero vector is not linearly independent as a set because $a_1 \cdot \veco = \veco$ for any scalar $a_1$. \\$v_1$ is linearly independent as a set because $v_1$ is not the zero vector, and therefore $a_1 \cdot v_1 = \veco$ implies $a_1 = 0$. \\It can be seen on the diagram that $v_1$ is not collinear with $v_2$, and likewise not with $v_3$, and so $\{v_1;v_2\}$ is linearly independent and $\{v_1;v_3\}$ is linearly independent. \\$v_2$ and $v_3$ appear to be collinear, so $\{v_2;v_3\}$ is not linearly independent(i.e. suppose $v_3 = 2\cdot v_2$; then 2\cdot v_2 + -1 \cdot v_3 = 0). \\$v_3$ is of course collinear with itself, so $\{v_3;v_3\}$ is not linearly independent. \\Finally, since $\{v_2;v_3\}$ is not linearly independent and is a subset of $\{v_1;v_2;v_3\}$, this last set cannot be linearly independent.  
}


\endedxproblem



\doedxvideo{A Proposition}{DK-9-MAIaA8}

\endedxvertical

\beginedxvertical{Linear Dependence Proposition}

\beginedxtext{Linear Dependence Equivalent Condition}

Let $\{v_1; v_2; \ldots v_n\}$ be vectors in a vector space $V$.  The list is linearly dependent
if and only if one of the vectors in the list can be expressed as a linear combination of the other 
vectors.  

\endedxtext

\beginedxproblem{True or False}{\dpa1}


True or False: Suppose the list $\{v_1; v_2; v_3; v_4\}$ is linearly dependent.  Then $v_4$ must be in the 
span of $\{v_1; v_2; v_3\}$.  

\edXabox{expect="False" options="True","False"}


\edXsolution{ The conclusion is too specific. We proved that if our list is linearly dependent, then at least one of the vectors will be in the span of the others. We can't claim that a particular vector in the list is in the span of the rest of the list, or that all vectors are in the spans of their list complements (without knowing more). Consider the problem on the previous tab with $v_1$, $v_2$, and $v_3$: it appears that $v_3$ is not in the span of $v_1$ and $v_2$, and yet the set of three is linearly dependent.
}


\endedxproblem





\beginedxproblem{Proving Linear Independence}{\dpa3}

Let's think about the definition of linear independence.  
Recall that a list of vectors $\{v_1; v_2; \ldots v_n\}$ in a vector space $V$ is 
linearly independent if the only way to pick scalars $a_1, a_2, \ldots a_n$ such that
$a_1v_1 + a_2v_2 + \ldots + a_nv_n = \veco$ is if $a_1 = a_2 = \ldots = a_n = 0$.  


Which of the following would be a way to prove that a list $\{v_1; v_2; \ldots v_n\}$ is linearly independent?
Check all that apply.

\edXabox{type="oldmultichoice" expect="Assume that $a_i \ne 0$ for at least one $i$ from 1 to $n$, and show $a_1v_1 + a_2v_2 + \ldots + a_nv_n \ne \veco$","Assume that $a_1v_1 + a_2v_2 + \ldots + a_nv_n = \veco$, and show that $a_i = 0$ for all $i$ from 1 to $n$" options="Assume that $a_i = 0$ for all $i$ from 1 to $n$, and show $a_1v_1 + a_2v_2 + \ldots + a_nv_n = \veco$","Assume that $a_i \ne 0$ for all $i$ from 1 to $n$, and show $a_1v_1 + a_2v_2 + \ldots + a_nv_n \ne \veco$","Assume that $a_i \ne 0$ for at least one $i$ from 1 to $n$, and show $a_1v_1 + a_2v_2 + \ldots + a_nv_n \ne \veco$","Assume that $a_1v_1 + a_2v_2 + \ldots + a_nv_n = \veco$, and show that $a_i = 0$ for all $i$ from 1 to $n$","Assume that $a_1v_1 + a_2v_2 + \ldots + a_nv_n \ne \veco$, and show that $a_i \ne 0$ for at least one $i$ from 1 to $n$"}


\edXsolution{ 
The approach in choice 1 won't prove linear independence, because the conclusion will be true regardless of the vectors in the list.
\\The approach in choice 2 won't prove linear independence, because even if our vector list passes the test in choice 2, there may yet exist some set of coefficients, not all zero but containing at least one zero, that gives a zero linear combination (i.e., the list could still be linearly dependent).
\\The approach in choice 3 will prove linear independence. If it's true that every set of coefficients, not all zero, will give a non-zero linear combination, then the only way to get a zero linear combination is with all zero coefficients, which is the definition of linear independence. 
\\The approach in choice 4 will prove linear independence. It simply uses the definition. (Notice that choices 3 and 4 are just contrapositives of each other.)
\\The approach in choice 5 won't prove linear independence, because the conclusion will be true regardless of the vectors in the list.
}


\endedxproblem



\beginedxproblem{Existence or Uniqueness?}{\dpa3}

Is the linear independence of a list of vectors an existence question, or a uniqueness question?

\edXabox{expect="Uniqueness" options="Existence","Uniqueness"}


\edXsolution{ 
A list of vectors is linearly independent if the {\keyb{\bf{only}}} way to write $\veco$ as a linear combination
of the list is when all coefficients are zero.  This is a uniqueness statement.  
}


\endedxproblem




\endedxvertical

\beginedxvertical{Determining Linear Independence in R^m}

\beginedxproblem{Non-trivial Solutions?}{\dpa2}

Use row reduction to determine how many solutions the equation $Ax = \veco$ has, where 
\[ A = \left[\begin{array}{ccc} 1 & 2 & 3 \\ -1 & 1 & 3 \\ 3 & 3 & 3 \\ 4 & 1 & -2 \\
5  & 3 & 1 \end{array} \right]. \]

\edXabox{expect="Infinitely many solutions" options="No solutions","Exactly one solution","Infinitely many
solutions"}



Is the list $\{v_1; v_2; v_3\}$ linearly independent, where the $v_i$ are given below?

\[v_1 = \left[\begin{array}{c} 1 \\ -1  \\ 3 \\ 4 \\5 \end{array} \right], 
v_2 = \left[\begin{array}{c} 2 \\ 1  \\ 3 \\ 1 \\ 3 \end{array} \right],  
v_3 = \left[\begin{array}{c} 3 \\ 3  \\ 3 \\ -2 \\ 1 \end{array} \right]. \]


\edXabox{expect="Linearly dependent" options="Linearly independent","Linearly dependent"}

\edXsolution{ 
First, we remind that there must always exist at least one solution to $Ax = \veco$. We will either have exactly one solution (and that solution will be $\veco$), or we will have infinitely many solutions (e.g., any scalar multiple of a solution to $Ax = \veco$ is also a solution to $Ax = \veco$). 
\\After row reduction, we have:
$A = \left[\begin{array}{ccc} 1 & 0 & -1 \\ 0 & 1 & 2 \\ 0 & 0 & 0 \\ 0 & 0 & 0 \\
0  & 0 & 0 \end{array} \right]$
\\We have only two pivots. The third column represents a free variable; $x_3$ can equal anything we choose. The equation has infinitely many solutions.
Note that, in the product $A \cdot x$, the columns of the matrix $A$ are vectors that are combined with the entries of $x$ as the weights:  $Ax = x_1v_1 + x_2v_2 + x_3v_3$. We have therefore shown that there are infinitely many sets $\{x_1; x_2; x_3\}$ that satisfy $x_1v_1 + x_2v_2 + x_3v_3 = 0$, and by definition, the list $\{v_1; v_2; v_3\}$ is linearly dependent.  
}
\endedxproblem





\beginedxproblem{Fill in the blank}{\dpa2}

What goes in the blank to make a correct statement?

If the matrix $A$ yields $\underline{\;\;\;\;\;\;\;\;\;\;}$ when row-reduced, then
the columns of $A$ cannot be linearly independent.  

\edXabox{type="multichoice" expect="a free variable" options="a row of all zeros","a free variable","either of the above"}

\edXsolution{ A free variable can be chosen to equal anything in a solution to $Ax = \veco$; therefore, the presence of a free variable implies that the columns of $A$ are not linearly independent.

\\Now suppose we have a 5x3 matrix, so that the columns represent 3 vectors in $\R^5$:
\\$\left[\begin{array}{ccc} 1 & 1 & 1 \\ 2 & 4 & 8 \\ 3 & 9 & 27 \\ 4 & 16 & 64 \\
5  & 25 & 125 \end{array} \right]$

\\If the columns are linearly independent, we have no free variables, and so there must be a pivot in every column. Since every pivot in row-reduced form is the only non-zero entry in its column, the row-reduced form of the matrix can only look like this:

\\$\left[\begin{array}{ccc} 1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 1 \\ 0 & 0 & 0 \\
0 & 0 & 0 \end{array} \right]$

\\So, a row-reduced matrix with linearly independent columns can have a row of all zeros, and in particular, if there are more rows than columns, it is guaranteed to have such a row.

}

\endedxproblem


\beginedxproblem{Fill in the blank 2}{\dpa2}

What goes in the blank to make a correct statement?

If the matrix $A$ has $\underline{\;\;\;\;\;\;\;\;\;\;}$, then
there must be a free variable.  

\edXabox{type="multichoice" expect="more columns than rows" options="more rows than columns","more columns than rows"}

\edXsolution{ 
Every row has at most one pivot, and every column has at most one pivot. Therefore, whichever is fewer, the number of rows or the number of columns, represents an upper bound on the possible number of pivots of a matrix. For this reason, if there are more columns than rows, there can't be a pivot in every column. As we've seen before, a column without a pivot represents a free variable. So a system with a coefficient matrix with more columns than rows must have a free variable. If there are more rows than columns, it is possible that every column has a pivot, and that there are no free variables in the system.
}

\endedxproblem


\beginedxproblem{Fill in the blank 3}{\dpa2}

Putting the previous two statements together, what goes in the blank to make a correct statement?  

A list of  $\underline{\;\;\;\;\;\;\;\;\;\;}$ cannot be linearly independent.

\edXabox{type="multichoice" expect="5 vectors in $\R^3$" options="3 vectors in $\R^5$","5 vectors in $\R^3$"}

\edXsolution{
A list of 5 vectors in $\R^3$ can be written as a 3x5 matrix, which has more columns than rows. As we've established, if such a matrix serves as the coefficient matrix of a system, the system will have a free variable, which means that the columns of the matrix are linearly dependent. 
}
\endedxproblem


\doedxvideo{Linear Independence in R^m}{hjQug5gZ2JM}


\endedxvertical

\beginedxvertical{Linearly Independent Lists in R^m}


\beginedxtext{Linear Independence in R^m}


We have just shown the following results:  

If $A$ is an $m\times n$ matrix with columns 
$v_1, v_2, \ldots v_n \in \R^m$, then the list $\{v_1; v_2; \ldots v_n\}$ is linearly independent
if and only if $A$ does not have a free variable.  

If $n>m$, then any list of $n$ vectors in $\R^m$ must be linearly dependent.  


\endedxtext





\beginedxproblem{Quick Picks}{\dpa2}

Without doing any row-reduction, you should be able to pick out three of the 
following lists of vectors that are linearly dependent.  Which three?  

\begin{enumerate}


\item
$\left\{ \left[ \begin{array}{c} 1 \\ 1 \\ 1 \end{array} \right]; 
\left[ \begin{array}{c} 1 \\ 1 \\ 0 \end{array} \right]; 
\left[ \begin{array}{c} 1 \\ 0 \\ 1 \end{array} \right] \right\}
$


\item
$\left\{\left[ \begin{array}{c} 1 \\ 2 \\ 3 \end{array} \right] ; 
\left[ \begin{array}{c} 0 \\ 0 \\ 0 \end{array} \right] ; 
\left[ \begin{array}{c} 2 \\ 5 \\ 7 \end{array} \right]\} $



\item
$\left\{\left[ \begin{array}{c} 1 \\ 2 \\ 1 \\ 4\end{array} \right] ; 
\left[ \begin{array}{c} 2 \\ 13 \\ 3 \\ 7\end{array} \right] ; 
\left[ \begin{array}{c} 0 \\ 1 \\ 5 \\ -3\end{array} \right] ;
\left[ \begin{array}{c} 15 \\ -2 \\ 6 \\ 2\end{array} \right] ;
\left[ \begin{array}{c} 5 \\ 3 \\ 8 \\ 11\end{array} \right] \right\} $



\item
$\left\{\left[ \begin{array}{c} 2 \\ 3 \\ 5 \\ 7 \\ 11 \end{array} \right] ;
\left[ \begin{array}{c} 1 \\ 2 \\ 3 \\ 4 \\5 \end{array} \right] ;
\left[ \begin{array}{c} 2 \\ 4 \\ 6 \\ 8 \\ 10 \end{array} \right] ; 
\left[ \begin{array}{c} 1 \\ 1 \\ 2 \\ 3 \\ 5 \end{array} \right] \right\} $

\item
$\left\{\left[ \begin{array}{c} 0 \\ 1 \\ 0\\ 2 \\ 3 \\ 0 \end{array} \right] ;
\left[ \begin{array}{c} 0 \\ 2 \\ 0\\ 7 \\ 1 \\ 0 \end{array} \right] ;
\left[ \begin{array}{c} 0 \\ 12 \\ 0\\ 23 \\ 35 \\ 0 \end{array} \right] \right\}$


\item
$\left\{\left[ \begin{array}{c} 1 \\ 1 \\ 1 \\ 1 \end{array} \right] ; 
\left[ \begin{array}{c} 1 \\ 1 \\ 2 \\ 1 \end{array} \right] ;
\left[ \begin{array}{c} 1 \\ 1 \\ 1 \\ 2 \end{array} \right] \right\}
$
\end{enumerate}




\edXabox{type="oldmultichoice" expect="B","C","D" options="A","B","C","D","E","F"}

\edXsolution{ Choice B has the zero vector and is therefore linearly dependent. Choice C has 5 vectors in $\R^4$ and is therefore linearly dependent (expressed as a matrix, there would be more columns than rows). Choice E has a pair of collinear vectors: the third vector is twice the second vector. The list in choice E is therefore linearly dependent. 
}

\endedxproblem


\endedxvertical







\beginedxvertical{Summarizing}



\doedxvideo{Completing the Chart}{Pumr8h6X7Gs}





\endedxvertical

